{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear output esc r y\n",
    "# https://scikit-learn.org/stable/modules/unsupervised_reduction.html\n",
    "# https://scikit-learn.org/stable/modules/feature_selection.html\n",
    "\n",
    "#import csv\n",
    "#with open('X_train.csv', newline='') as csvfile:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "xdata = pd.read_csv ('X_train.csv', nrows=5)\n",
    "ydata = pd.read_csv('y_train.csv',nrows=5)\n",
    "\n",
    "merged = pd.concat([xdata, ydata['y']], axis=1, sort=False)\n",
    "print(xdata.drop(['id'],axis=1))\n",
    "#print(ydata['y'])\n",
    "#print(np.transpose(ydata.values)[1:][0])\n",
    "#print(len(np.transpose(xdata.values)[1:]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ca42f210e1e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mselector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRFECV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mselector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mranking_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    550\u001b[0m         scores = parallel(\n\u001b[1;32m    551\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m             for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    550\u001b[0m         scores = parallel(\n\u001b[1;32m    551\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m             for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36m_rfe_single_fit\u001b[0;34m(rfe, estimator, X, y, train, test, scorer)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_safe_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     return rfe._fit(\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         _score(estimator, X_test[:, features], y_test, scorer)).scores_\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, step_score)\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;31m# that have not been eliminated yet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstep_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m             \u001b[0msupport_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mranks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mranking_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupport_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(estimator, features)\u001b[0m\n\u001b[1;32m     33\u001b[0m     return rfe._fit(\n\u001b[1;32m     34\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         _score(estimator, X_test[:, features], y_test, scorer)).scores_\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer)\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m     error_msg = (\"scoring must return a number, got %s (%s) \"\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_passthrough_scorer\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_passthrough_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;34m\"\"\"Function that wraps estimator.score\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36mr2_score\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    582\u001b[0m     \"\"\"\n\u001b[1;32m    583\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0;32m--> 584\u001b[0;31m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[1;32m    585\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 646\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     98\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                     (type_err,\n\u001b[0;32m--> 100\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m    101\u001b[0m             )\n\u001b[1;32m    102\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# Recursive feature elimination\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "  \n",
    "xdata = pd.read_csv('x_train_mean.csv',nrows=50)\n",
    "ydata = pd.read_csv('y_train.csv',nrows=50)\n",
    "\n",
    "X=xdata.drop(['id'],axis=1)\n",
    "y=ydata['y']\n",
    "\n",
    "estimator = SVR(kernel=\"linear\")\n",
    "\n",
    "selector = RFECV(estimator, step=1, cv=5)\n",
    "selector = selector.fit(X, y)\n",
    "selector.support_\n",
    "selector.ranking_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We started with 831 features but retained only 448 of them!\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 831 but corresponding boolean dimension is 832",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-b196180343da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"We started with {0} features but retained only {1} of them!\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkepler_X_trans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mcolumns_retained_FromMode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4290\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4291\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4292\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4293\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpromote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 831 but corresponding boolean dimension is 832"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://www.kaggle.com/residentmario/automated-feature-selection-with-sklearn\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "  \n",
    "xdata = pd.read_csv('x_train_mean.csv')\n",
    "ydata = pd.read_csv('y_train.csv')\n",
    "\n",
    "X=xdata.drop(['id'],axis=1)\n",
    "y=ydata['y']\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X, y)\n",
    "\n",
    "pd.Series(clf.feature_importances_, index=X.columns[0:]).plot.bar(color='steelblue', figsize=(12, 6))\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "trans = SelectFromModel(clf, threshold='median')\n",
    "kepler_X_trans = trans.fit_transform(X, y)\n",
    "\n",
    "print(\"We started with {0} features but retained only {1} of them!\".format(X.shape[1] - 1, kepler_X_trans.shape[1]))\n",
    "columns_retained_FromMode = X.iloc[:, 1:].columns[trans.get_support()].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We started with 832 features but retained only 416 of them!\n"
     ]
    }
   ],
   "source": [
    "#GenericUnivariateSelect\n",
    "# https://www.kaggle.com/residentmario/automated-feature-selection-with-sklearn\n",
    "\n",
    "from sklearn.feature_selection import GenericUnivariateSelect\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "  \n",
    "xdata = pd.read_csv('x_train_mean.csv')\n",
    "ydata = pd.read_csv('y_train.csv')\n",
    "\n",
    "X=xdata.drop(['id'],axis=1)\n",
    "y=ydata['y']\n",
    "\n",
    "trans = GenericUnivariateSelect(score_func=lambda X, y: X.mean(axis=0), mode='percentile', param=50)\n",
    "chars_X_trans = trans.fit_transform(X, y)\n",
    "\n",
    "print(\"We started with {0} features but retained only {1} of them!\".format(X.shape[1], chars_X_trans.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We started with 831 features but retained only 416 of them!\n"
     ]
    }
   ],
   "source": [
    "#pt 2\n",
    "from sklearn.feature_selection import GenericUnivariateSelect\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "  \n",
    "xdata = pd.read_csv('x_train_mean.csv',nrows=20)\n",
    "ydata = pd.read_csv('y_train.csv',nrows=20)\n",
    "\n",
    "X=xdata.drop(['id'],axis=1)\n",
    "y=ydata['y']\n",
    "\n",
    "#kepler_mutual_information = mutual_info_classif(X, y)\n",
    "\n",
    "trans = GenericUnivariateSelect(score_func=mutual_info_classif, mode='percentile', param=50)\n",
    "kepler_X_trans = trans.fit_transform(X, y)\n",
    "\n",
    "print(\"We started with {0} features but retained only {1} of them!\".format(X.shape[1] - 1, kepler_X_trans.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Regression\n",
    "# http://www.webgraphviz.com then copy .dot file\n",
    "\n",
    "# import numpy package for arrays and stuff \n",
    "import numpy as np  \n",
    "  \n",
    "# import matplotlib.pyplot for plotting our result \n",
    "import matplotlib.pyplot as plt \n",
    "  \n",
    "# import pandas for importing csv files  \n",
    "import pandas as pd  \n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor  \n",
    "  \n",
    "xdata = pd.read_csv('x_train_mean.csv')\n",
    "ydata = pd.read_csv('y_train.csv')\n",
    "\n",
    "X=xdata.drop(['id'],axis=1)\n",
    "y=ydata['y']\n",
    "    \n",
    "# create a regressor object \n",
    "regressor = DecisionTreeRegressor(random_state = 0)  \n",
    "  \n",
    "# fit the regressor with X and Y data \n",
    "regressor.fit(X, y) \n",
    "\n",
    "\n",
    "# import export_graphviz \n",
    "from sklearn.tree import export_graphviz  \n",
    "  \n",
    "# export the decision tree to a tree.dot file \n",
    "# for visualizing the plot easily anywhere \n",
    "export_graphviz(regressor, out_file ='tree.dot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum value in each column : \n",
      "6.503016520821267e+18\n",
      "Maximum value in each column : \n",
      "-3.76020076348273e+22\n",
      "False\n",
      "True\n",
      "Best alpha using built-in LassoCV: 31006708878259097960448.000000\n",
      "Best score using built-in LassoCV: 0.000000\n"
     ]
    }
   ],
   "source": [
    "#Feature selection using embedded method\n",
    "import pandas as pd\n",
    "import scipy.stats as sst\n",
    "#importing libraries\n",
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n",
    "\n",
    "xdata = pd.read_csv('x_train_mean.csv',nrows=10)\n",
    "ydata = pd.read_csv('y_train.csv',nrows=10)\n",
    "\n",
    "X=xdata.drop(['id'],axis=1)\n",
    "y=ydata['y']\n",
    "\n",
    "reg = LassoCV()\n",
    "reg.fit(X, y)\n",
    "print(\"Best alpha using built-in LassoCV: %f\" % reg.alpha_)\n",
    "print(\"Best score using built-in LassoCV: %f\" %reg.score(X,y))\n",
    "coef = pd.Series(reg.coef_, index = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          x183      x537\n",
      "x183  1.000000 -0.083316\n",
      "x537 -0.083316  1.000000\n"
     ]
    }
   ],
   "source": [
    "# Feature selection using Pearson Correlation\n",
    "#https://towardsdatascience.com/feature-selection-with-pandas-e3690ad8504b\n",
    "import pandas as pd\n",
    "import scipy.stats as sst\n",
    "#importing libraries\n",
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n",
    "\n",
    "xdata = pd.read_csv('X_train.csv')\n",
    "ydata = pd.read_csv('y_train.csv')\n",
    "\n",
    "merged = pd.concat([xdata, ydata['y']], axis=1, sort=False)\n",
    "\n",
    "#df1 = merged.iloc[:, 0:]\n",
    "#plt.figure(figsize=(len(merged),len(merged)))\n",
    "cor = merged.corr()\n",
    "#sns.heatmap(cor,annot=True,cmap=plt.cm.Reds)\n",
    "\n",
    "#Correlation with output variable\n",
    "cor_target = abs(cor[\"y\"])\n",
    "#Selecting highly correlated features\n",
    "relevant_features = cor_target[cor_target>0.5]\n",
    "relevant_features\n",
    "\n",
    "print(merged[['x183','x537']].corr()) # not correlated so we don't drop either\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection using Chi2 test\n",
    "#Doesn't work since its a cmbi of features\n",
    "\n",
    "import pandas as pd\n",
    "import scipy.stats as sst\n",
    "\n",
    "xdata = pd.read_csv('X_train.csv')\n",
    "ydata = pd.read_csv('y_train.csv')\n",
    "\n",
    "xdatabycol = np.transpose(xdata.values)[1:] #line 0 -> x0 etc.\n",
    "ydatabycol = np.transpose(ydata.values)[1:][0]\n",
    "\n",
    "for attr_index in range(len(xdatabycol)):\n",
    "    #attr_sol = np.column_stack(xdatabycol[attr_index],ydatabycol)\n",
    "    crosstab = pd.crosstab(xdatabycol[attr_index],ydatabycol)\n",
    "    chi2,p,_,_ = sst.chi2_contingency(crosstab)\n",
    "    if (p > 0.05):\n",
    "        print(attr_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "df = pd.read_csv('X_train.csv',nrows=5)\n",
    "\n",
    ">>> \n",
    ">>> X, y = load_iris(return_X_y=True)\n",
    ">>> X.shape\n",
    "(150, 4)\n",
    ">>> clf = ExtraTreesClassifier(n_estimators=50)\n",
    ">>> clf = clf.fit(X, y)\n",
    ">>> clf.feature_importances_  \n",
    "array([ 0.04...,  0.05...,  0.4...,  0.4...])\n",
    ">>> model = SelectFromModel(clf, prefit=True)\n",
    ">>> X_new = model.transform(X)\n",
    ">>> X_new.shape               \n",
    "(150, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.13.1. Removing features with low variance\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv ('x_train_KNN.csv',nrows=10)\n",
    "\n",
    "#p = 0.80\n",
    "#sel = VarianceThreshold(threshold=(p * (1 - p)))\n",
    "\n",
    "mapper = DataFrameMapper([(df.columns, StandardScaler())])\n",
    "scaled_features = mapper.fit_transform(df.copy())\n",
    "scaled_features_df = pd.DataFrame(scaled_features, index=df.index, columns=df.columns)\n",
    "\n",
    "#print(df_fitted)\n",
    "\n",
    "print(scaled_features_df == df)\n",
    "print(scaled_features_df)\n",
    "    \n",
    "#for index, row in df.iterrows():\n",
    "#    print(row)\n",
    "#    for attr in row:\n",
    "#        print(row(attr))\n",
    "    \n",
    "#    print(\"---------------\")\n",
    "   \n",
    "\n",
    "\n",
    "# for attr in range(df.shape[1]):\n",
    "#        print(row)\n",
    "#        print(attr)\n",
    "#        if (dfcopy[row][attr] != df_fitted[row][attr]):\n",
    "#            print(i)\n",
    "#            print(dfcopy[row][attr])\n",
    "#            print(df_fitted[row][attr])\n",
    "\n",
    "np.array_equal(scaled_features_df,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##unsupervised dim reduc https://scikit-learn.org/stable/modules/unsupervised_reduction.html\n",
    "\n",
    "## FEATURE AGGLOMERATION\n",
    "\n",
    "from sklearn.cluster import FeatureAgglomeration\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df=pd.read_csv ('x_train_KNN.csv',nrows=10)\n",
    "labels = pd.read_csv('Y_train.csv',nrows=10)\n",
    "\n",
    "#set n_clusters to 2, the output will be two columns of agglomerated features ( iris has 4 features)\n",
    "agglo=FeatureAgglomeration(n_clusters=2).fit_transform(labels)\n",
    "\n",
    "print(agglo)\n",
    "print(agglo[:,0])\n",
    "\n",
    "#plotting\n",
    "#color=[]\n",
    "#for i in labels:\n",
    "#    if i=='Iris-setosa':\n",
    "#        color.append('g')\n",
    "#    if  i=='Iris-versicolor':\n",
    "#        color.append('b')\n",
    "#    if i=='Iris-virginica':\n",
    "#        color.append('r')\n",
    "#plt.scatter(agglo[:,0],agglo[:,1],c=color)\n",
    "#plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
